{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Bunny ICP",
   "metadata": {
    "colab_type": "text",
    "id": "OE4xjKWgtIX2",
    "cell_id": "00000-a21c7b2e-3ec4-42ae-ad36-1236eeaeb8dc",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdXAerwV13rQ",
    "cell_id": "00001-ca672b35-7279-4dab-9dd0-6ab261e18cc8",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c6531ebd",
    "execution_start": 1634998191531,
    "execution_millis": 1523,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "# Imports\nimport numpy as np\nimport open3d as o3d\n\nfrom pydrake.all import (\n  RigidTransform, RotationMatrix, PointCloud, Rgba\n)\nfrom manipulation import running_as_notebook, FindResource\nfrom manipulation.meshcat_cpp_utils import StartMeshcat",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00002-dc7840e8-f9c6-4dd4-910c-da53f162a543",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6d42057f",
    "execution_start": 1634998193930,
    "execution_millis": 5,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "# Start the visualizer.\nmeshcat = StartMeshcat()",
   "outputs": [
    {
     "name": "stdout",
     "text": "Meshcat is now available at https://94ea9120-f1f5-434b-831e-4f569f0fea0c.deepnoteproject.com\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Problem Description\nIn the lecture, we learned about the Iterative Closest Point (ICP) algorithm. In this exercise, you will implement the ICP algorithm to solve the standard Stanford Bunny problem!\n\n**These are the main steps of the exercise:**\n1. Implement the ```least_squares_transform``` function to optimize transformation given correspondence\n2. Implement the ```icp``` algorithm using the functions implemented above.\n\nLet's first visualize the point clouds of Stanford bunny in meshcat!",
   "metadata": {
    "colab_type": "text",
    "id": "jigwRNW7tIYQ",
    "cell_id": "00003-1e8bbd39-74d8-4974-998e-284c8796fbdb",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "VnQvdI6nOl4d",
    "outputId": "866d6e69-d188-4669-8b01-825d8e616b0d",
    "cell_id": "00004-15fcccb7-6b91-414d-9d24-858134e1fed5",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "84989217",
    "execution_start": 1634998206625,
    "execution_millis": 6,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "# Visualize Stanford Bunny \npoints = np.asarray(o3d.io.read_point_cloud(\n    FindResource(\"models/bunny/bun_zipper_res2.ply\")).points)\n\n# Center and rotate the raw points.\nX_WFile = RigidTransform(RotationMatrix.MakeZRotation(np.pi/2), [0, 0, 0]) @ RigidTransform(RotationMatrix.MakeXRotation(np.pi/2), [0, 0, -0.05])\npoints = X_WFile.multiply(points.T).T\n\ncloud = PointCloud(points.shape[0])\ncloud.mutable_xyzs()[:] = points.T\n\n# Pose for the blue bunny\nX_blue = RigidTransform(RotationMatrix.MakeXRotation(np.pi/6), [-.1, .1, .1])\n\npointcloud_model = points\npointcloud_scene = X_blue.multiply(points.T).T\n\nmeshcat.Delete()\nmeshcat.SetProperty(\"/Background\",'visible', False)\nmeshcat.SetProperty(\"/Cameras/default/rotated/<object>\",\"zoom\", 10.5)\nmeshcat.SetObject(\"red_bunny\", cloud, size=0.01, rgba=Rgba(1.0, 0, 0))\nmeshcat.SetTransform(\"red_bunny\", RigidTransform())\nmeshcat.SetObject(\"blue_bunny\", cloud, size=0.01, rgba=Rgba(0, 0, 1.0))\nmeshcat.SetTransform(\"blue_bunny\", X_blue)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Point cloud registration with known correspondences\n\nIn this section, you will follow the [derivation](http://manipulation.csail.mit.edu/pose.html#section3) to solve the optimization problem below. \n\n$$\\begin{aligned} \\min_{p\\in\\mathbb{R}^3,R\\in\\mathbb{R}^{3\\times3}} \\quad & \\sum_{i=1}^{N_s} \\| p + R \\hspace{.1cm} {^Op^{m_{c_i}}} - p^{s_i}\\|^2, \\\\ s.t. \\quad & RR^T = I, \\quad \\det(R)=1\\end{aligned}$$\n    \nThe goal is to find the transform that registers the point clouds of the model and the scene, assuming the correspondence is known.  You may refer to the implementation from [colab](https://colab.research.google.com/github/RussTedrake/manipulation/blob/master/pose.ipynb#scrollTo=AHfxMwrvb1mz) and the explanation from [textbook](http://manipulation.csail.mit.edu/pose.html#section4).\n\nIn the cell below, implement the ```least_squares_transform``` nethod.",
   "metadata": {
    "colab_type": "text",
    "id": "abo92_2stIYW",
    "cell_id": "00005-db3923d0-19b0-4dcb-9f11-821e606b06b1",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ll_FlqVotIYX",
    "cell_id": "00006-1426ce5e-cd5a-4689-a108-c33b73a34afe",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f850bd32",
    "execution_start": 1634998208408,
    "execution_millis": 0,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "def least_squares_transform(scene, model) -> RigidTransform:\n    '''\n    Calculates the least-squares best-fit transform that maps corresponding\n    points scene to model.\n    Args:\n      scene: Nx3 numpy array of corresponding points\n      model: Nx3 numpy array of corresponding points\n    Returns:\n      X_BA: A RigidTransform object that maps point_cloud_A on to point_cloud_B \n            such that\n                        X_BA.multiply(model) ~= scene,\n    '''\n    X_BA = RigidTransform()\n    ##################\n    # your code here\n    N_s = scene.shape[0]\n    # Centre points\n    pom_ = model.mean(axis=0) # Don't use this (1/N_s)*np.sum(model,axis=0)\n    ps_ = scene.mean(axis=0)# Don't use this (1/N_s) * np.sum(scene,axis=0)\n    W = (scene - ps_).T @ (model - pom_)\n    # breakpoint()\n    # print(W.shape)\n    u, s, vh = np.linalg.svd(W)\n    det_uv = np.linalg.det(u @ vh)\n    D = [[1,0,0],[0,1,0],[0,0,det_uv]]\n    \n    R_star = u @ D @ vh\n    # print(R_star)\n    \n    p_star = ps_ - (R_star @ pom_)\n    X_BA = RigidTransform(RotationMatrix(R_star),p_star)\n    ##################\n    return X_BA",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Point correspondence from closest point\nThe ```least_squares_transform``` function assumes that the point correspondence is known. Unfortunately, this is often not the case, so we will have to estimate the point correspondence as well. A common heuristics for estimating point correspondence is the closest point/nearest neighbor. \n\nWe have implemented the closest neighbors using [Open3d's implementation](http://www.open3d.org/docs/release/python_api/open3d.geometry.KDTreeFlann.html), which uses [k-d trees](https://en.wikipedia.org/wiki/K-d_tree).",
   "metadata": {
    "colab_type": "text",
    "id": "IejlqJ3vtIYg",
    "cell_id": "00007-d55a3e7b-e056-4daa-bfcf-0220623f0477",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-bGj1a1OkbU",
    "cell_id": "00008-12162936-ae2a-448a-819e-2b9d718d7cc4",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e77bd763",
    "execution_start": 1634998209715,
    "execution_millis": 5,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "def nearest_neighbors(scene, model):\n    '''\n    Find the nearest (Euclidean) neighbor in model for each\n    point in scene\n    Args:\n        scene: Nx3 numpy array of points\n        model: Mx3 numpy array of points\n    Returns:\n        distances: (N, ) numpy array of Euclidean distances from each point in\n            scene to its nearest neighbor in model.\n        indices: (N, ) numpy array of the indices in model of each\n            scene point's nearest neighbor - these are the c_i's\n    '''\n    distances = np.empty(scene.shape[0], dtype=float)\n    indices = np.empty(scene.shape[0], dtype=int)\n    \n    kdtree = o3d.geometry.KDTreeFlann(model.T)\n    for i in range(model.shape[0]):\n        nn = kdtree.search_knn_vector_3d(scene[i,], 1)\n        indices[i] = nn[1][0]\n        distances[i] = np.linalg.norm(scene[i,:] - model[indices[i],:])\n\n    return distances, indices",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Iterative Closest Point (ICP)\nNow you should be able to register two point clouds iteratively by first finding/updating the estimate of point correspondence with ```nearest_neighbors``` and then computing the transform using ```least_squares_transform```. You may refer to the explanation from [textbook](http://manipulation.csail.mit.edu/pose.html#section4).\n\n**In the cell below, complete the implementation of ICP algorithm using the  ```nearest_neighbors``` and ```least_squares_transform``` methods from above.**",
   "metadata": {
    "colab_type": "text",
    "id": "KtvN0kBntIYo",
    "cell_id": "00009-a24d6887-e4c7-426e-94e2-c6bb461ee394",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wETDMjk4tIYp",
    "cell_id": "00010-686968b3-f7c2-4fe9-a45f-898351a4aa14",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "49d632a5",
    "execution_start": 1634998851808,
    "execution_millis": 3,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "def icp(scene, model, max_iterations=20, tolerance=1e-3):\n    '''\n    Perform ICP to return the correct relative transform between two set of points.\n    Args:\n        scene: Nx3 numpy array of points\n        model: Mx3 numpy array of points\n        max_iterations: max amount of iterations the algorithm can perform.\n        tolerance: tolerance before the algorithm converges.\n    Returns:\n      X_BA: A RigidTransform object that maps point_cloud_A on to point_cloud_B \n            such that\n                        X_BA.multiply(model) ~= scene,\n      mean_error: Mean of all pairwise distances. \n      num_iters: Number of iterations it took the ICP to converge. \n    '''\n    X_BA = RigidTransform()\n\n    mean_error = 0\n    num_iters = 0\n    prev_error = 0\n    \n    while True:\n        num_iters += 1  \n          \n        # your code here\n        ##################\n        d, i = nearest_neighbors(scene,X_BA.multiply(model.T).T)\n        X_BA = least_squares_transform(scene,model[i])\n        mean_error = d.mean() # Modify to add mean error.\n        ##################\n\n        if abs(mean_error - prev_error) < tolerance or num_iters >= max_iterations:\n            break\n\n        prev_error = mean_error\n\n        meshcat.SetTransform(\"red_bunny\", X_BA)\n\n    return X_BA, mean_error, num_iters",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Now you should be able to visualize the registration of the Stanford bunny! Have fun!",
   "metadata": {
    "colab_type": "text",
    "id": "WChfoIVWtIYy",
    "cell_id": "00011-322d6389-5341-468d-8a0f-2ca645fba58c",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8oIuMsCDMJM",
    "cell_id": "00012-0ecc303b-c10f-4f30-b98c-e4cbed6f33b0",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f4c8917e",
    "execution_start": 1634998853158,
    "execution_millis": 4790,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "icp(pointcloud_scene, pointcloud_model, max_iterations=30, tolerance=1e-5);",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## How will this notebook be Graded?##\n\nIf you are enrolled in the class, this notebook will be graded using [Gradescope](www.gradescope.com). You should have gotten the enrollement code on our announcement in Piazza. \n\nFor submission of this assignment, you must: \n- Download and submit the notebook `bunny_icp.ipynb` to Gradescope's notebook submission section, along with your notebook for the other problems.\n\nWe will evaluate the local functions in the notebook to see if the function behaves as we have expected. For this exercise, the rubric is as follows:\n- [3 pts] `least_squares_transform` must be implemented correctly. \n- [3 pts] `icp` must be implemented correctly.",
   "metadata": {
    "colab_type": "text",
    "id": "ucRnypactIY2",
    "cell_id": "00013-7884bd61-57d1-4179-89d2-ab4614993286",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lfmnYSMItIY3",
    "outputId": "21d3a0f9-0e63-4eb7-cc7f-d95677e38c5e",
    "cell_id": "00014-049deb55-9efe-42a9-8e3a-68279f2678a9",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4d4faa8d",
    "execution_start": 1634998860104,
    "execution_millis": 5111,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "from manipulation.exercises.pose.test_icp import TestICP\nfrom manipulation.exercises.grader import Grader \n\nGrader.grade_output([TestICP], [locals()], 'results.json')\nGrader.print_test_results('results.json')",
   "outputs": [
    {
     "name": "stdout",
     "text": "Total score is 6/6.\n\nScore for Test icp implementation is 3/3.\n\nScore for Test least square transform is 3/3.\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "tags": [],
    "cell_id": "00015-eac6d27d-6d55-4e1b-9652-f9c81008f6bd",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=94ea9120-f1f5-434b-831e-4f569f0fea0c' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 1,
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "bunny_icp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "deepnote_notebook_id": "c105f887-ae39-477c-931a-842c93378177",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}